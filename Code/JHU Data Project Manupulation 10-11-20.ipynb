{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts the JHU Cumulative Case Count Data to Daily Case Count Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "- [X] Figure out how to fix the control measure obs that are recorded as '.'\n",
    "- [X] Need to explore the missingness of the Oxford data. Sort the countries by GDP and examine what the missingness matrix looks like. **If you could run imputation on this data then you would have a major leg up on the other paper working on the similar topic. (on to of the other benefits to your paper)**\n",
    "- [X] Write the code that merges in the time series data for the diffent control measures\n",
    "- [X] Write the code merges in the Country Safety Index data\n",
    "- [X] Continue to update this **[file](https://1drv.ms/x/s!AjWX5HOdYY23kf9x5S7g8LKLGlseVg?e=992nsi)** of data source locations \n",
    "- [X] Write the code that lets you convert the US data to long\n",
    "- [X] Write the code that converts the column names in the Oxford data set to match the column names in the JHU dat\n",
    "- [X] Write the code that merges the countries to their offical alpha 3 code in the JHU: **[Link to Codes](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes)**\n",
    "- [X] **ALTERNATIVE TO ABOVE** use python-Levenshtein [Docs](https://rawgit.com/ztane/python-Levenshtein/master/docs/Levenshtein.html) distance to match similar country names \n",
    "> would still need to pair the high probability matches \n",
    "- [X] Write the code transposes the combined data with the control measures included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_col_renamer(dframe):\n",
    "    \"\"\"\n",
    "    Tips: This fuction will remove special characters from column headers, replace spaces with columns, \n",
    "    and make all heading lower case\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dframe : TYPE Pandas dataframe\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dframe.columns = dframe.columns.str.lower()\n",
    "    dframe.columns = dframe.columns.str.replace('\\s{2,}',' ',regex=True).str.replace('-',' ').str.replace(' ','_').str.replace('[^A-Za-z0-9_]+','',regex=True)\n",
    "    return dframe\n",
    "data_path = r'..\\csse_covid_19_data\\csse_covid_19_time_series'\n",
    "out_data_path = r'..\\Modified Data Sets'\n",
    "control_data_path = '..\\Control Data'\n",
    "case_pre = pd.read_csv(f'{data_path}/time_series_covid19_confirmed_global.csv')\n",
    "death_pre = pd.read_csv(f'{data_path}/time_series_covid19_deaths_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the JHU COVID Case Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_pre_us = pd.read_csv(f'{data_path}/time_series_covid19_confirmed_US.csv')\n",
    "# death_pre_us = pd.read_csv(f'{data_path}/time_series_covid19_deaths_US.csv')\n",
    "\n",
    "\n",
    "file_list = os.listdir(out_data_path)\n",
    "for files in file_list:\n",
    "    if files.find('.xlsx') >= 0:\n",
    "        shutil.move(f'{out_data_path}/{files}',f'{out_data_path}/ARCHIVE/{files}')\n",
    "def DF_Transform(df, outcome):\n",
    "    global data_path\n",
    "    global out_data_path\n",
    "    \n",
    "    # Data Cleaning\n",
    "    df.drop(labels={'Lat','Long'},axis=1, inplace = True)\n",
    "#     df.loc[df['Country/Region'].str.contains('Congo'), 'Country/Region'] ='Congo'\n",
    "    df.loc[df['Country/Region'].str.contains('Korea, South',flags= re.IGNORECASE), 'Country/Region']= 'South Korea'\n",
    "    df.loc[df['Country/Region'] == ('US'), 'Country/Region']= 'United States'\n",
    "    df.loc[df['Country/Region'].str.contains('taiwan',flags= re.IGNORECASE), 'Country/Region']= 'taiwan'\n",
    "    # Data Manipulation\n",
    "    df = df.groupby(by='Country/Region').sum().T.apply(lambda x: x-x.shift(1),axis=0)\n",
    "    df.rename(columns={'Country/Region':'Date'},inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'index':'date'},inplace= True)\n",
    "    df.date = pd.to_datetime(df.date).dt.date\n",
    "#     df['var'] = outcome[16:]\n",
    "    \n",
    "    filename = f'{out_data_path}/{outcome} (Through {df.date.max()}).xlsx'\n",
    "    df.to_excel(filename, index=False)\n",
    "    return df\n",
    "case = DF_Transform(case_pre, 'Global COVID-19 Case Count')\n",
    "death = DF_Transform(death_pre, 'Global COVID-19 Death Count')\n",
    "# case = DF_Transform(case_pre_us, 'US COVID-19 Case Count')\n",
    "# death = DF_Transform(death_pre_us, 'US COVID-19 Death Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_lag_d = case.set_index('date')\n",
    "case_lag1 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-1),axis=0).reset_index()\n",
    "case_lag2 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-2),axis=0).reset_index()\n",
    "case_lag3 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-3),axis=0).reset_index()\n",
    "case_lag4 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-4),axis=0).reset_index()\n",
    "case_lag5 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-5),axis=0).reset_index()\n",
    "case_lag6 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-6),axis=0).reset_index()\n",
    "case_lag7 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-7),axis=0).reset_index()\n",
    "case_lag8 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-8),axis=0).reset_index()\n",
    "case_lag9 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-9),axis=0).reset_index()\n",
    "case_lag10 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-10),axis=0).reset_index()\n",
    "case_lag11 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-11),axis=0).reset_index()\n",
    "case_lag12 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-12),axis=0).reset_index()\n",
    "case_lag13 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-13),axis=0).reset_index()\n",
    "case_lag14 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-14),axis=0).reset_index()\n",
    "case_lag15 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-15),axis=0).reset_index()\n",
    "case_lag16 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-16),axis=0).reset_index()\n",
    "case_lag17 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-17),axis=0).reset_index()\n",
    "case_lag18 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-18),axis=0).reset_index()\n",
    "case_lag19 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-19),axis=0).reset_index()\n",
    "case_lag20 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-20),axis=0).reset_index()\n",
    "case_lag21 = case_lag_d.iloc[0:,1:].apply(lambda x: x.shift(-21),axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_maker(dset, var):\n",
    "    name_list = dset.columns.to_list()[1:]\n",
    "    long_df = pd.DataFrame(columns = {'date', var, 'country'})\n",
    "    for name in name_list:\n",
    "        df = dset.filter(items={name, 'date'})\n",
    "        df['country'] = name\n",
    "        df.rename(columns={name:var},inplace = True)\n",
    "        long_df = pd.concat([long_df, df],axis=0)\n",
    "    long_df.date = pd.to_datetime(long_df.date)\n",
    "    return long_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_case = long_maker(case, 'case_count')\n",
    "long_death = long_maker(death, 'death_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_1 = long_maker(case_lag1,'case1')\n",
    "long_2 = long_maker(case_lag2,'case2')\n",
    "long_3 = long_maker(case_lag3,'case3')\n",
    "long_4 = long_maker(case_lag4,'case4')\n",
    "long_5 = long_maker(case_lag5,'case5')\n",
    "long_6 = long_maker(case_lag6,'case6')\n",
    "long_7 = long_maker(case_lag7,'case7')\n",
    "long_8 = long_maker(case_lag8,'case8')\n",
    "long_9 = long_maker(case_lag9,'case9')\n",
    "long_10 = long_maker(case_lag10,'case10')\n",
    "long_11 = long_maker(case_lag11,'case11')\n",
    "long_12 = long_maker(case_lag12,'case12')\n",
    "long_13 = long_maker(case_lag13,'case13')\n",
    "long_14 = long_maker(case_lag14,'case14')\n",
    "long_15 = long_maker(case_lag15,'case15')\n",
    "long_16 = long_maker(case_lag16,'case16')\n",
    "long_17 = long_maker(case_lag17,'case17')\n",
    "long_18 = long_maker(case_lag18,'case18')\n",
    "long_19 = long_maker(case_lag19,'case19')\n",
    "long_20 = long_maker(case_lag20,'case20')\n",
    "long_21 = long_maker(case_lag21,'case21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the Oxford Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correcting_Col_Names(infile_path, dset):\n",
    "    infile = pd.read_csv(infile_path)\n",
    "    # og_col_list = infile.columns.to_list()\n",
    "    df = pd.DataFrame(infile.columns.to_list())\n",
    "    df['col'] = df[2:].apply(lambda x: pd.to_datetime(x).dt.strftime('X%m/X%d/%Y').str.replace('X0','').str.replace('X',''))\n",
    "    df['col'][0] = 'country'\n",
    "    df['col'][1] = 'country_code'\n",
    "    cols = df.col.to_list()\n",
    "    control = pd.read_csv(infile_path, names = cols, skiprows={0:1})\n",
    "    indexNames = control[ control['country_code'].isna()].index\n",
    "    control.drop(indexNames, inplace=True)\n",
    "    df = controls_transpose(control, dset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controls_transpose(dset, var):\n",
    "    import re\n",
    "    df = dset.T\n",
    "    df.columns = df.iloc[0]\n",
    "    df.columns =df.columns.str.lower()\n",
    "    df.drop(axis=0, index = {'country', 'country_code'},inplace = True)\n",
    "    df = df.reset_index().rename(columns={'index':'date'})\n",
    "    df = long_maker(df, var)\n",
    "    df.loc[df['country'].str.contains('cape verde',flags= re.IGNORECASE), 'country']= 'cabo verde'\n",
    "    df.loc[df['country'].str.contains('taiwan',flags= re.IGNORECASE), 'country']= 'taiwan'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_measures_path = r'../../../covid-policy-tracker/data'\n",
    "school = Correcting_Col_Names(f'{c_measures_path}/timeseries/c1_schoolclosing.csv', 'school_close')\n",
    "work = Correcting_Col_Names(f'{c_measures_path}/timeseries/c2_workplaceclosing.csv', 'work_close')\n",
    "pub_events = Correcting_Col_Names(f'{c_measures_path}/timeseries/c3_cancelpublicevents.csv', 'public_events')\n",
    "gatherings = Correcting_Col_Names(f'{c_measures_path}/timeseries/c4_restrictionsongatherings.csv', 'large_gather')\n",
    "pub_transpo = Correcting_Col_Names(f'{c_measures_path}/timeseries/c5_closepublictransport.csv', 'public_transpo')\n",
    "stay_home = Correcting_Col_Names(f'{c_measures_path}/timeseries/c6_stayathomerequirements.csv' ,'stay_home')\n",
    "domestic_travel = Correcting_Col_Names(f'{c_measures_path}/timeseries/c7_domestictravel.csv' ,'domestic_travel')\n",
    "int_travel = Correcting_Col_Names(f'{c_measures_path}/timeseries/c8_internationaltravel.csv' ,'internat_travel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-10-21 00:00:00')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_merger(df):\n",
    "    global long_df\n",
    "    long_df = long_df.merge(df, on=['date', 'country'])\n",
    "    return long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = df_merger(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>case_count</th>\n",
       "      <th>country</th>\n",
       "      <th>death_count</th>\n",
       "      <th>school_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42075</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42076</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42077</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42078</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42079</th>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>taiwan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42080 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  case_count      country  death_count school_close\n",
       "0     2020-01-22         NaN  afghanistan          NaN            0\n",
       "1     2020-01-23         0.0  afghanistan          0.0            0\n",
       "2     2020-01-24         0.0  afghanistan          0.0            0\n",
       "3     2020-01-25         0.0  afghanistan          0.0            0\n",
       "4     2020-01-26         0.0  afghanistan          0.0            0\n",
       "...          ...         ...          ...          ...          ...\n",
       "42075 2020-10-06         3.0       taiwan          0.0            0\n",
       "42076 2020-10-07         2.0       taiwan          0.0            0\n",
       "42077 2020-10-08         1.0       taiwan          0.0            0\n",
       "42078 2020-10-09         3.0       taiwan          0.0            0\n",
       "42079 2020-10-10         0.0       taiwan          0.0            0\n",
       "\n",
       "[42080 rows x 5 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = long_case.merge(long_death, on=['date', 'country'])\n",
    "# long_df = long_df.merge(school, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(work, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(pub_events, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(gatherings, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(pub_transpo, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(stay_home, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(domestic_travel, on=['date', 'country'],how='outer')\n",
    "# long_df = long_df.merge(int_travel, on=['date', 'country'],how='outer')\n",
    "# long_df[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']] = long_df[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']].apply(lambda x: x.str.replace('.','999'))\n",
    "# long_df[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']] = long_df[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']].fillna(999)\n",
    "# long_df[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']] = long_df[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']].astype(int)\n",
    "# long_df.loc[long_df.school_close == 999, 'school_close'] = np.nan\n",
    "# long_df.loc[long_df.work_close == 999, 'work_close'] = np.nan\n",
    "# long_df.loc[long_df.public_events == 999, 'public_events'] = np.nan\n",
    "# long_df.loc[long_df.large_gather == 999, 'large_gather'] = np.nan\n",
    "# long_df.loc[long_df.public_transpo == 999, 'public_transpo'] = np.nan\n",
    "# long_df.loc[long_df.stay_home == 999, 'stay_home'] = np.nan\n",
    "# long_df.loc[long_df.domestic_travel == 999, 'domestic_travel'] = np.nan\n",
    "# long_df.loc[long_df.internat_travel == 999, 'internat_travel'] = np.nan\n",
    "\n",
    "# long_df[['school_close','work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']] = long_df.groupby('country')[['school_close',\n",
    "#        'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "#        'stay_home', 'domestic_travel', 'internat_travel']].apply(lambda x: x.ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "59849    0.0\n",
       "59850    0.0\n",
       "59851    0.0\n",
       "59852    0.0\n",
       "59853    0.0\n",
       "Name: work_close, Length: 59854, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.work_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_summary = long_df.groupby('country').case_count.agg(['mean','median','std', 'max'])\n",
    "death_summary = long_df.groupby('country').case_count.agg(['mean','median','std', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_var_path = '../Control Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_name_clean(df):\n",
    "    import re\n",
    "#     df.loc[(df['country'].str.contains('Congo',re.IGNORECASE)) & (~df['country'].str.contains('dem',re.IGNORECASE)) , 'country'] ='congo'\n",
    "    df.loc[(df['country'].str.contains('korea, s',flags= re.IGNORECASE)) & (df['country'].str.contains('south',flags= re.IGNORECASE)), 'country']= 'south korea'\n",
    "    df.loc[df['country'].str.contains('rep')& (df['country'].str.contains('congo',flags= re.IGNORECASE)) ,'country']= 'democratic republic of congo'\n",
    "    df.loc[df['country'] == ('US'), 'country']= 'united states'\n",
    "    df.loc[df['country'].str.contains('ivoire|ivory coast',flags= re.IGNORECASE), 'country']= 'cote d\\'ivoire'\n",
    "    df.loc[df['country'].str.contains('venezuela',flags= re.IGNORECASE), 'country']= 'venezuela'\n",
    "    df.loc[df['country'].str.contains('and principe',flags= re.IGNORECASE), 'country']= 'sao tome and principe'\n",
    "    df.loc[df['country'].str.contains('and the grenadines',flags= re.IGNORECASE), 'country']= 'saint vincent and the grenadines'\n",
    "    df.loc[df['country'].str.contains('kitts and nevis',flags= re.IGNORECASE), 'country']= 'saint kitts and nevis'\n",
    "    df.loc[df['country'].str.contains('bahamas',flags= re.IGNORECASE), 'country']= 'bahamas'\n",
    "    df.loc[df['country'].str.contains('yemen',flags= re.IGNORECASE), 'country']= 'yemen'\n",
    "    df.loc[df['country'].str.contains('gambia',flags= re.IGNORECASE), 'country']= 'gambia'\n",
    "    df.loc[df['country'].str.contains('hong kong',flags= re.IGNORECASE), 'country']= 'hong kong'\n",
    "    df.loc[df['country'].str.contains('macao',flags= re.IGNORECASE), 'country']= 'macao'\n",
    "    df.loc[df['country'].str.contains('iran',flags= re.IGNORECASE), 'country']= 'iran'\n",
    "    df.loc[df['country'].str.contains('lucia',flags= re.IGNORECASE), 'country']= 'saint lucia'\n",
    "    df.loc[df['country'].str.contains('lao pdr',flags= re.IGNORECASE), 'country']= 'laos'\n",
    "    df.loc[df['country'].str.contains('egypt',flags= re.IGNORECASE), 'country']= 'egypt'\n",
    "    df.loc[df['country'].str.contains('korea, rep.',flags= re.IGNORECASE), 'country']= 'south korea'\n",
    "    df.loc[df['country'].str.contains('states of america',flags= re.IGNORECASE), 'country']= 'united states'\n",
    "    df.loc[df['country'].str.contains('east timor',flags= re.IGNORECASE), 'country']= 'timor-leste'\n",
    "    df.loc[df['country'].str.contains('russia',flags= re.IGNORECASE), 'country']= 'russia'\n",
    "    df.loc[df['country'].str.contains('brunei',flags= re.IGNORECASE), 'country']= 'brunei'\n",
    "    df.loc[df['country'].str.contains('korea, dem. people\\'s rep',flags= re.IGNORECASE), 'country']= 'north korea'\n",
    "    dset = df.copy()\n",
    "    return dset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID Regional Safety Assessment Data\n",
    "safety = pd.read_excel(f'{control_var_path}/COVID-19_Regional_Safety_Assessment.xlsx')\n",
    "safety.columns = safety.columns.str.lower()\n",
    "safety.rename(columns={'country/ region':'country'}, inplace=True)\n",
    "safety.country = safety.country.str.lower()\n",
    "safety = country_name_clean(safety)\n",
    "\n",
    "#World Bank GDP Data\n",
    "gdp = pd.read_excel(f'{control_var_path}/Global GDP.xlsx')\n",
    "gdp.drop(columns='Unnamed: 4', inplace=True)\n",
    "gdp.columns = gdp.columns.str.lower()\n",
    "gdp.rename(columns={'economy':'country'}, inplace=True)\n",
    "gdp.country = gdp.country.str.lower()\n",
    "\n",
    "og_data = pd.read_excel('..\\..\\Country Response Paper\\Original Documents\\Country Responses-selected\\Country Responses Dataset 7.28.20.xlsx',sheet_name = 'Country Responses')\n",
    "og_data.index = og_data['Country/Region']\n",
    "og_data = og_data.iloc[0:,19:]\n",
    "og_data = og_data.reset_index(drop=False).rename(columns={'Country/Region':'country'})\n",
    "og_data.columns = og_data.columns.str.lower()\n",
    "og_data = stats_col_renamer(og_data)\n",
    "og_data.dropna(how='all',inplace=True)\n",
    "og_data.country = og_data.country.str.lower()\n",
    "\n",
    "safety = country_name_clean(safety)\n",
    "gdp = country_name_clean(gdp)\n",
    "og_data = country_name_clean(og_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'population', 'ages_65_and_above__of_total_population',\n",
       "       'female__of_total', 'diabetes_prevalence__of_population_ages_20_to_79',\n",
       "       'obese__of_adult_population', 'htn_prevalence',\n",
       "       'smoking_prevalence_ages_15', 'cancer_prevalence_',\n",
       "       'hiv_prevalence__of_population_ages_15_49', 'copd_dalys_per_100000',\n",
       "       'sars_experience_0_no_1_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and evaluating the smoking dataset from Our World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_world_importer(filename,sheet, year=2017):\n",
    "    df = pd.read_excel(f'{control_data_path}\\\\{filename}.xlsx', sheet_name = sheet)\n",
    "    df = stats_col_renamer(df)\n",
    "    df = df.loc[df.year == year]\n",
    "    df.drop(columns=['entity','year'],inplace=True)\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoking Data\n",
    "smk_die_rate = our_world_importer('share-deaths-smoking', 'death-rate-smoking')\n",
    "smk_die_prop = our_world_importer('share-deaths-smoking', 'share-deaths-smoking')\n",
    "#HIV Data\n",
    "hiv_prev = our_world_importer('hiv-data','share-of-population-infected-wi')\n",
    "hiv_death = our_world_importer('hiv-data','hiv-death-rates')\n",
    "#Obesity Data\n",
    "obese = our_world_importer('share-of-deaths-obesity','share-of-deaths-obesity')\n",
    "#Population Data\n",
    "pop = our_world_importer('projected-population-by-country', 'projected-population-by-country',year=2020)\n",
    "#Age Data\n",
    "age = our_world_importer('median-age','median-age',year=2020)\n",
    "#Diabetes Data\n",
    "diabet = our_world_importer('diabetes-prevalence', 'diabetes-prevalence')\n",
    "mers = pd.read_excel(f'{control_data_path}\\MERS-SARS.xlsx',sheet_name='MERS')\n",
    "sars = pd.read_excel(f'{control_data_path}\\MERS-SARS.xlsx',sheet_name='SARS')\n",
    "mers = stats_col_renamer(mers)\n",
    "sars = stats_col_renamer(sars)\n",
    "sars.drop(columns=['number_of_hcw_affected_', 'date_onset_first_probable_case',\n",
    "       'date_onset_last_probable_case','case_fatality_ratio_','female', 'male','areas','median_age_range'],inplace=True)\n",
    "mers.drop(columns='country',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Merge a lot of DataFrames\n",
    "> Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [smk_die_rate, smk_die_prop,hiv_prev, hiv_death, obese, pop, age, diabet, mers, sars]\n",
    "merge = partial(pd.merge,on='code', how='outer')\n",
    "control = reduce(merge,dfs)\n",
    "control[['mers_case_count',\n",
    "       'sars_case_count', 'number_of_deathsa', 'number_of_imported_cases',\n",
    "       'percent_of_imported_cases']] = control[['mers_case_count',\n",
    "       'sars_case_count', 'number_of_deathsa', 'number_of_imported_cases',\n",
    "       'percent_of_imported_cases']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control = smk_die_rate.copy()\n",
    "# control = control.merge(smk_die_prop, on='code', how='outer')\n",
    "# control = control.merge(hiv_prev, on='code', how='outer')\n",
    "# control = control.merge(hiv_death, on='code', how='outer')\n",
    "# control = control.merge(obese, on='code', how='outer')\n",
    "# control = control.merge(pop, on='code', how='outer')\n",
    "# control = control.merge(age, on='code', how='outer')\n",
    "# control = control.merge(diabet, on='code', how='outer')\n",
    "# control = control.merge(mers, on='code', how='outer')\n",
    "# control = control.merge(sars, on='code', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol = control.merge(gdp,left_on='code',right_on='countrycode',how='outer')\n",
    "long_df_newcontrol = long_df_newcontrol.merge(long_df, on=['country'],how='outer')\n",
    "long_df_newcontrol = long_df_newcontrol.merge(safety, on=['country'],how='outer')\n",
    "long_df_newcontrol = long_df_newcontrol.merge(og_data, on=['country'],how='outer')\n",
    "long_df_newcontrol = stats_col_renamer(long_df_newcontrol)\n",
    "long_df_newcontrol.rename(columns={'us_dollars_in_mil':'gdp_in_mil_us', 'ranking':'gdp_rank'},inplace=True)\n",
    "long_df_newcontrol.drop(columns={'global_region','code'},inplace=True)\n",
    "long_df_newcontrol.columns = long_df_newcontrol.columns.str.replace('__','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['deaths_smoking_sex_both_age_age_standardized_rate',\n",
       "       'smoking_ihme_2019',\n",
       "       'prevalence_hivaids_sex_both_age_15_49_years_percent',\n",
       "       'deaths_hivaids_sex_both_age_age_standardized_rate',\n",
       "       'obesity_ihme_2019',\n",
       "       'population_by_country_and_region_historic_and_projections_gapminder_hyde_un',\n",
       "       'un_population_division_median_age_2017',\n",
       "       'diabetes_prevalence_of_population_ages_20_to_79_x', 'mers_case_count',\n",
       "       'sars_case_count', 'number_of_deathsa', 'number_of_imported_cases',\n",
       "       'percent_of_imported_cases', 'countrycode', 'gdp_rank', 'country',\n",
       "       'gdp_in_mil_us', 'date', 'case_count', 'death_count', 'school_close',\n",
       "       'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
       "       'stay_home', 'domestic_travel', 'internat_travel',\n",
       "       'quarantine_efficiency', 'gov_efficiency', 'monitoring_and_detection',\n",
       "       'healthcare_readiness', 'country_vulnerability',\n",
       "       'emergency_preparedness', 'total_score', 'population',\n",
       "       'ages_65_and_above_of_total_population', 'female_of_total',\n",
       "       'diabetes_prevalence_of_population_ages_20_to_79_y',\n",
       "       'obese_of_adult_population', 'htn_prevalence',\n",
       "       'smoking_prevalence_ages_15', 'cancer_prevalence_',\n",
       "       'hiv_prevalence_of_population_ages_15_49', 'copd_dalys_per_100000',\n",
       "       'sars_experience_0_no_1_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df_newcontrol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_order = ['date',  'country','case_count', 'death_count', 'school_close',\n",
    "       'work_close', 'public_events', 'large_gather', 'public_transpo',\n",
    "       'stay_home', 'domestic_travel', 'internat_travel', 'population',\n",
    "       'ages_65_and_above_of_total_population', 'female_of_total',\n",
    "       'diabetes_prevalence_of_population_ages_20_to_79',\n",
    "       'obese_of_adult_population', 'htn_prevalence',\n",
    "       'smoking_prevalence_ages_15', 'cancer_prevalence_',\n",
    "       'hiv_prevalence_of_population_ages_1549', 'copd_dalys_per_100000',\n",
    "       'sars_experience_0_no_1_yes', 'quarantine_efficiency', 'gov_efficiency',\n",
    "       'monitoring_and_detection', 'healthcare_readiness',\n",
    "       'country_vulnerability', 'emergency_preparedness', 'total_score',\n",
    "       'countrycode', 'gdp_rank', 'gdp_in_mil_us'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = ['country','countrycode','date','case_count','death_count',\n",
    "#      'school_close', 'domestic_travel','internat_travel','large_gather', 'public_events',\n",
    "#      'stay_home', 'work_close' 'public_transpo','gdp_rank','gdp_in_mil_us','smoking_ihme_2019',\n",
    "#      'population_by_country_and_region_historic_and_projections_gapminder_hyde__un',\n",
    "#      'prevalence_hivaids_sex_both_age_15_49_years_percent', \n",
    "#      'deaths_hivaids_sex_both_age_age_standardized_rate', 'deaths_smoking_sex_both_age_age_standardized_rate',\n",
    "#      'ages_65_and_above_of_total_population','htn_prevalence', 'copd_dalys_per_100000', 'obesity_ihme_2019',\n",
    "#      'country_vulnerability','emergency_preparedness','gov_efficiency','healthcare readiness',\n",
    "#      'monitoring and detection', 'quarantine_efficiency', 'total_score',\n",
    "#      'mers_case_count', 'sars_case_count', 'number_of_deathsa', \n",
    "#      'number_of_imported_cases', 'percent_of_imported_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol.countrycode = long_df_newcontrol.countrycode.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60778, 46)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df_newcontrol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol = long_df_newcontrol.filter(items=['country','countrycode','date','case_count','death_count',\n",
    "'school_close', 'domestic_travel','internat_travel','large_gather', 'public_events',\n",
    "'stay_home', 'work_close' ,'public_transpo',\n",
    "'gdp_rank', 'gdp_in_mil_us','smoking_ihme_2019', 'population_by_country_and_region_historic_and_projections_gapminder_hyde_un',\n",
    "'un_population_division_median_age_2017','ages_65_and_above_of_total_population',\n",
    "'prevalence_hivaids_sex_both_age_15_49_years_percent',\n",
    "'deaths_hivaids_sex_both_age_age_standardized_rate', \n",
    "'diabetes_prevalence_of_population_ages_20_to_79_x',\n",
    "'deaths_smoking_sex_both_age_age_standardized_rate','cancer_prevalence_',\n",
    "'htn_prevalence', 'copd_dalys_per_100000', 'obesity_ihme_2019',\n",
    "'country_vulnerability','emergency_preparedness','gov_efficiency','healthcare readiness',\n",
    "'monitoring and detection', 'quarantine_efficiency', 'total_score',\n",
    "'mers_case_count', 'sars_case_count', 'number_of_deathsa', 'number_of_imported_cases', 'percent_of_imported_cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol.rename(columns={'population_by_country_and_region_historic_and_projections_gapminder_hyde_un':'pop_2020','deaths_hivaids_sex_both_age_age_standardized_rate':'deaths_hivaids_sex_both_age',\n",
    "                                  'diabetes_prevalence_of_population_ages_20_to_79_x':'diabetes_prev_ages_20_to_79',\n",
    "                                  'cancer_prevalence_':'cancer_prevalence'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = long_df_newcontrol.date.max().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SARS/MERS Experience Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol.mers_case_count = long_df_newcontrol.mers_case_count.fillna(0)\n",
    "long_df_newcontrol.sars_case_count = long_df_newcontrol.sars_case_count.fillna(0)\n",
    "long_df_newcontrol['mers_sars_max'] = long_df_newcontrol[['mers_case_count', 'sars_case_count']].max(axis=1)\n",
    "long_df_newcontrol['mers_sars_sum'] = long_df_newcontrol[['mers_case_count', 'sars_case_count']].sum(axis=1)\n",
    "long_df_newcontrol['mers_sars_exp1'] = 0\n",
    "long_df_newcontrol['mers_sars_exp5'] = 0\n",
    "long_df_newcontrol['mers_sars_exp10'] = 0\n",
    "long_df_newcontrol['mers_sars_exp20'] = 0\n",
    "long_df_newcontrol['mers_sars_exp100'] = 0\n",
    "long_df_newcontrol['mers_sars_exp200'] = 0\n",
    "long_df_newcontrol['mers_sars_exp300'] = 0\n",
    "long_df_newcontrol['mers_sars_exp400'] = 0\n",
    "long_df_newcontrol['mers_sars_exp500'] = 0\n",
    "long_df_newcontrol['mers_sars_exp1000'] = 0\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 1, 'mers_sars_exp1' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 5, 'mers_sars_exp5' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 10, 'mers_sars_exp10' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 20, 'mers_sars_exp20' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 100, 'mers_sars_exp100' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 200, 'mers_sars_exp200' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 300, 'mers_sars_exp300' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 400, 'mers_sars_exp400' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 500, 'mers_sars_exp500' ] = 1\n",
    "long_df_newcontrol.loc[long_df_newcontrol.mers_sars_max >= 1000, 'mers_sars_exp1000' ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol['dayoweek'] = long_df_newcontrol.date.dt.dayofweek\n",
    "long_df_newcontrol['week'] = long_df_newcontrol.date.dt.weekofyear\n",
    "long_df_newcontrol['month'] = long_df_newcontrol.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'countrycode', 'date', 'case_count', 'death_count',\n",
       "       'school_close', 'domestic_travel', 'internat_travel', 'large_gather',\n",
       "       'public_events', 'stay_home', 'work_close', 'public_transpo',\n",
       "       'gdp_rank', 'gdp_in_mil_us', 'smoking_ihme_2019', 'pop_2020',\n",
       "       'un_population_division_median_age_2017',\n",
       "       'ages_65_and_above_of_total_population',\n",
       "       'prevalence_hivaids_sex_both_age_15_49_years_percent',\n",
       "       'deaths_hivaids_sex_both_age', 'diabetes_prev_ages_20_to_79',\n",
       "       'deaths_smoking_sex_both_age_age_standardized_rate',\n",
       "       'cancer_prevalence', 'htn_prevalence', 'copd_dalys_per_100000',\n",
       "       'obesity_ihme_2019', 'country_vulnerability', 'emergency_preparedness',\n",
       "       'gov_efficiency', 'quarantine_efficiency', 'total_score',\n",
       "       'mers_case_count', 'sars_case_count', 'number_of_deathsa',\n",
       "       'number_of_imported_cases', 'percent_of_imported_cases',\n",
       "       'mers_sars_max', 'mers_sars_sum', 'mers_sars_exp1', 'mers_sars_exp5',\n",
       "       'mers_sars_exp10', 'mers_sars_exp20', 'mers_sars_exp100',\n",
       "       'mers_sars_exp200', 'mers_sars_exp300', 'mers_sars_exp400',\n",
       "       'mers_sars_exp500', 'mers_sars_exp1000', 'dayoweek', 'week', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df_newcontrol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_week = pd.DataFrame()\n",
    "long_df_week = long_df_newcontrol[['country','case_count', 'death_count','week']].groupby(['country','week']).sum()\n",
    "con = long_df_newcontrol[['country','work_close','school_close', 'domestic_travel', \n",
    "                          'internat_travel', 'large_gather','public_events', \n",
    "                          'stay_home', 'gdp_rank','gdp_in_mil_us','week','smoking_ihme_2019',\n",
    "                          'pop_2020', 'un_population_division_median_age_2017',\n",
    "                          'ages_65_and_above_of_total_population',\n",
    "                          'prevalence_hivaids_sex_both_age_15_49_years_percent',\n",
    "                          'deaths_hivaids_sex_both_age', 'diabetes_prev_ages_20_to_79',\n",
    "                          'deaths_smoking_sex_both_age_age_standardized_rate',\n",
    "                          'cancer_prevalence', 'htn_prevalence', 'copd_dalys_per_100000',\n",
    "                          'obesity_ihme_2019', 'country_vulnerability', 'emergency_preparedness',\n",
    "                          'gov_efficiency', 'quarantine_efficiency', 'total_score',\n",
    "                          'mers_case_count', 'sars_case_count', 'number_of_deathsa',\n",
    "                          'number_of_imported_cases', 'percent_of_imported_cases',\n",
    "                          'mers_sars_max', 'mers_sars_sum', 'mers_sars_exp1', 'mers_sars_exp5',\n",
    "                          'mers_sars_exp10', 'mers_sars_exp20', 'mers_sars_exp100',\n",
    "                          'mers_sars_exp200','mers_sars_exp300','mers_sars_exp400','mers_sars_exp500',\n",
    "                          'mers_sars_exp1000']].groupby(['country','week']).apply(lambda x: x.mode())\n",
    "con.drop(columns=['week','country'], inplace=True)\n",
    "con.reset_index(inplace=True)\n",
    "long_df_week.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    53336.000000\n",
       "mean         0.863244\n",
       "std          0.950036\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max          3.000000\n",
       "Name: stay_home, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df_newcontrol.stay_home.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_week = long_df_week.merge(con, on=['country','week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_newcontrol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_week.to_excel(f'{out_data_path}\\\\Final Weekly COVID Data Set (Through {date}) (ver2).xlsx',index=False)\n",
    "long_df_newcontrol.to_excel(f'{out_data_path}\\\\Final COVID Data Set (Through {date}) (ver2).xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to work out country linking stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_check(q,l):\n",
    "    from fuzzywuzzy import fuzz,process\n",
    "    from Levenshtein import distance,ratio\n",
    "    import pandas as pd\n",
    "    jhu = []\n",
    "    similar = []\n",
    "    query = []\n",
    "    for countries in q:\n",
    "        results = process.extractOne(countries,list(jhu_country)) \n",
    "        if results[1] < 100:\n",
    "            jhu.append(results[0])\n",
    "            similar.append(results[1])\n",
    "            query.append(countries)\n",
    "    output = pd.DataFrame({'query_country':query, \n",
    "                          'similarity':similar,\n",
    "                           'jhu_country':jhu                       \n",
    "                          })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of the country names from each data set\n",
    "jhu_country = long_case.country.unique()\n",
    "ox_country = school.country.unique()\n",
    "gdp_country = gdp.country\n",
    "safe_country = safety.country\n",
    "og_country = og_data.country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country Name Cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oxford Data Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox_check = similar_check(ox_country ,jhu_country)\n",
    "ox_check.sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP Data Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_check = similar_check(gdp_country ,jhu_country)\n",
    "gdp_check.sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety Data Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_check = similar_check(safe_country ,jhu_country)\n",
    "safe_check.sort_values(by='similarity', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OG Data Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_check = similar_check(og_country ,jhu_country)\n",
    "og_check.sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Grave Yard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Oxford Control Measures Data Set (Ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from fuzzywuzzy import fuzz,process\n",
    "# from Levenshtein import distance,ratio\n",
    "# import pandas as pd\n",
    "# jhu = []\n",
    "# similar = []\n",
    "# ox = []\n",
    "# for countries in ox_country:\n",
    "#     results = process.extractOne(countries,list(jhu_country)) \n",
    "#     if results[1] < 100:\n",
    "#         jhu.append(results[0])\n",
    "#         similar.append(results[1])\n",
    "#         ox.append(countries)\n",
    "# output = pd.DataFrame({'oxford_country':ox, \n",
    "#                       'similarity':similar,\n",
    "#                        'jhu_country':jhu                       \n",
    "#                       })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
