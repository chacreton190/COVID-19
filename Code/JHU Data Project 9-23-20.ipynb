{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts the JHU Cumulative Case Count Data to Daily Case Count Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "- [X] Write the code that lets you convert the US data to long\n",
    "- [X] Write the code that converts the column names in the Oxford data set to match the column names in the JHU dat\n",
    "- [ ] Write the code that merges the countries to their offical alpha 3 code in the JHU: **[Link to Codes](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes)**\n",
    "- [ ] **ALTERNATIVE TO ABOVE** use python-Levenshtein [Docs](https://rawgit.com/ztane/python-Levenshtein/master/docs/Levenshtein.html) distance to match similar country names \n",
    "> would still need to pair the high probability matches \n",
    "- [ ] Need to explore the missingness of the Oxford data. Sort the countries by GDP and examine what the missingness matrix looks like. **If you could run imputation on this data then you would have a major leg up on the other paper working on the similar topic. (on to of the other benefits to your paper)**\n",
    "- [ ] Write the code that merges in the time series data for the diffent control measures\n",
    "- [ ] Write the code transposes the combined data with the control measures included\n",
    "- [ ] Write the code merges in the Country Safety Index data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the JHU COVID Case Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "data_path = r'..\\csse_covid_19_data\\csse_covid_19_time_series'\n",
    "out_data_path = r'..\\Modified Data Sets'\n",
    "\n",
    "case_pre = pd.read_csv(f'{data_path}/time_series_covid19_confirmed_global.csv')\n",
    "death_pre = pd.read_csv(f'{data_path}/time_series_covid19_deaths_global.csv')\n",
    "\n",
    "\n",
    "# case_pre_us = pd.read_csv(f'{data_path}/time_series_covid19_confirmed_US.csv')\n",
    "# death_pre_us = pd.read_csv(f'{data_path}/time_series_covid19_deaths_US.csv')\n",
    "\n",
    "import shutil\n",
    "file_list = os.listdir(out_data_path)\n",
    "for files in file_list:\n",
    "    if files.find('.xlsx') >= 0:\n",
    "        shutil.move(f'{out_data_path}/{files}',f'{out_data_path}/ARCHIVE/{files}')\n",
    "def DF_Transform(df, outcome):\n",
    "    global data_path\n",
    "    global out_data_path\n",
    "    \n",
    "    # Data Cleaning\n",
    "    df.drop(labels={'Lat','Long'},axis=1, inplace = True)\n",
    "    df.loc[df['Country/Region'].str.contains('Congo'), 'Country/Region'] ='Congo'\n",
    "    df.loc[df['Country/Region'].str.contains('Korea, South'), 'Country/Region']= 'South Korea'\n",
    "    \n",
    "    # Data Manipulation\n",
    "    df = df.groupby(by='Country/Region').sum().T.apply(lambda x: x-x.shift(1),axis=0)\n",
    "    df.rename(columns={'Country/Region':'Date'},inplace=True)\n",
    "    df.columns = df.columns.str.replace(' ','_').str.lower()\n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'index':'date'},inplace= True)\n",
    "    df.date = pd.to_datetime(df.date).dt.date\n",
    "#     df['var'] = outcome[16:]\n",
    "    \n",
    "    filename = f'{out_data_path}/{outcome} (Through {df.date.max()}).xlsx'\n",
    "    df.to_excel(filename, index=False)\n",
    "    return df\n",
    "case = DF_Transform(case_pre, 'Global COVID-19 Case Count')\n",
    "death = DF_Transform(death_pre, 'Global COVID-19 Death Count')\n",
    "# case = DF_Transform(case_pre_us, 'US COVID-19 Case Count')\n",
    "# death = DF_Transform(death_pre_us, 'US COVID-19 Death Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_maker(dset, var):\n",
    "    name_list = dset.columns.to_list()[1:]\n",
    "    long_df = pd.DataFrame(columns = {'date', var, 'country'})\n",
    "    for name in name_list:\n",
    "        df = dset.filter(items={name, 'date'})\n",
    "        df['country'] = name\n",
    "        df.rename(columns={name:var},inplace = True)\n",
    "        long_df = pd.concat([long_df, df],axis=0)\n",
    "    long_df.date = pd.to_datetime(long_df.date)\n",
    "    return long_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_case = long_maker(case, 'case_count')\n",
    "long_death = long_maker(death, 'death_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the Oxford Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correcting_Col_Names(infile_path, dset):\n",
    "    infile = pd.read_csv(infile_path)\n",
    "    # og_col_list = infile.columns.to_list()\n",
    "    df = pd.DataFrame(infile.columns.to_list())\n",
    "    df['col'] = df[2:].apply(lambda x: pd.to_datetime(x).dt.strftime('X%m/X%d/%Y').str.replace('X0','').str.replace('X',''))\n",
    "    df['col'][0] = 'country'\n",
    "    df['col'][1] = 'country_code'\n",
    "    cols = df.col.to_list()\n",
    "    control = pd.read_csv(infile_path, names = cols, skiprows={0:1})\n",
    "    indexNames = control[ control['country_code'].isna()].index\n",
    "    control.drop(indexNames, inplace=True)\n",
    "    df = controls_transpose(control, dset)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controls_transpose(dset, var):\n",
    "    df = dset.T\n",
    "    df.columns = df.iloc[0]\n",
    "    df.columns =df.columns.str.lower()\n",
    "    df.drop(axis=0, index = {'country', 'country_code'},inplace = True)\n",
    "    df = df.reset_index().rename(columns={'index':'date'})\n",
    "    df = long_maker(df, var)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_measures_path = r'../../../covid-policy-tracker/data'\n",
    "school = Correcting_Col_Names(f'{c_measures_path}/timeseries/c1_schoolclosing.csv', 'school_close')\n",
    "work = Correcting_Col_Names(f'{c_measures_path}/timeseries/c2_workplaceclosing.csv', 'work_close')\n",
    "pub_events = Correcting_Col_Names(f'{c_measures_path}/timeseries/c3_cancelpublicevents.csv', 'public_events')\n",
    "gatherings = Correcting_Col_Names(f'{c_measures_path}/timeseries/c4_restrictionsongatherings.csv', 'large_gather')\n",
    "pub_transpo = Correcting_Col_Names(f'{c_measures_path}/timeseries/c5_closepublictransport.csv', 'public_transpo')\n",
    "stay_home = Correcting_Col_Names(f'{c_measures_path}/timeseries/c6_stayathomerequirements.csv' ,'stay_home')\n",
    "domestic_travel = Correcting_Col_Names(f'{c_measures_path}/timeseries/c7_domestictravel.csv' ,'domestic_travel')\n",
    "int_travel = Correcting_Col_Names(f'{c_measures_path}/timeseries/c8_internationaltravel.csv' ,'internat_travel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-09-22 00:00:00')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = long_case.merge(long_death, on=['date', 'country'])\n",
    "long_df = long_df.merge(school, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(work, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(pub_events, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(gatherings, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(pub_transpo, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(stay_home, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(domestic_travel, on=['date', 'country'],how='outer')\n",
    "long_df = long_df.merge(int_travel, on=['date', 'country'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>case_count</th>\n",
       "      <th>country</th>\n",
       "      <th>death_count</th>\n",
       "      <th>school_close</th>\n",
       "      <th>work_close</th>\n",
       "      <th>public_events</th>\n",
       "      <th>large_gather</th>\n",
       "      <th>public_transpo</th>\n",
       "      <th>stay_home</th>\n",
       "      <th>domestic_travel</th>\n",
       "      <th>internat_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45707</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45708</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45709</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45710</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45711</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45438</th>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>14.0</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45439</th>\n",
       "      <td>2020-09-19</td>\n",
       "      <td>25.0</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45440</th>\n",
       "      <td>2020-09-20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60872</th>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60873</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60874 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  case_count      country  death_count school_close  \\\n",
       "45707 2020-01-01         NaN  afghanistan          NaN            0   \n",
       "45708 2020-01-02         NaN  afghanistan          NaN            0   \n",
       "45709 2020-01-03         NaN  afghanistan          NaN            0   \n",
       "45710 2020-01-04         NaN  afghanistan          NaN            0   \n",
       "45711 2020-01-05         NaN  afghanistan          NaN            0   \n",
       "...          ...         ...          ...          ...          ...   \n",
       "45438 2020-09-18        14.0     zimbabwe          0.0            .   \n",
       "45439 2020-09-19        25.0     zimbabwe          1.0            .   \n",
       "45440 2020-09-20        11.0     zimbabwe          0.0            .   \n",
       "60872 2020-09-21         NaN     zimbabwe          NaN            .   \n",
       "60873 2020-09-22         NaN     zimbabwe          NaN            .   \n",
       "\n",
       "      work_close public_events large_gather public_transpo stay_home  \\\n",
       "45707          0             0            0              0         0   \n",
       "45708          0             0            0              0         0   \n",
       "45709          0             0            0              0         0   \n",
       "45710          0             0            0              0         0   \n",
       "45711          0             0            0              0         0   \n",
       "...          ...           ...          ...            ...       ...   \n",
       "45438          .             .            .              .         .   \n",
       "45439          .             .            .              .         .   \n",
       "45440          .             .            .              .         .   \n",
       "60872          .             .            .              .         .   \n",
       "60873          .             .            .              .         .   \n",
       "\n",
       "      domestic_travel internat_travel  \n",
       "45707               0               0  \n",
       "45708               0               0  \n",
       "45709               0               0  \n",
       "45710               0               0  \n",
       "45711               0               0  \n",
       "...               ...             ...  \n",
       "45438               .               .  \n",
       "45439               .               .  \n",
       "45440               .               .  \n",
       "60872               .               .  \n",
       "60873               .               .  \n",
       "\n",
       "[60874 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.sort_values(by=['country', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying to work out country linking stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_measures = pd.read_csv(f'{c_measures_path}/OxCGRT_latest_allchanges.csv')\n",
    "control_measures.columns = control_measures.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox_country = control_measures.countryname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_country = case_pre['Country/Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox_country.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_country.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz,process\n",
    "from Levenshtein import distance,ratio\n",
    "import pandas as pd\n",
    "jhu = []\n",
    "similar = []\n",
    "ox = []\n",
    "for countries in ox_country:\n",
    "    results = process.extractOne(countries,list(jhu_country)) \n",
    "    if results[1] < 100:\n",
    "        jhu.append(results[0])\n",
    "        similar.append(results[1])\n",
    "        ox.append(countries)\n",
    "output = pd.DataFrame({'oxford_country':ox, \n",
    "                      'similarity':similar,\n",
    "                       'jhu_country':jhu                       \n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Grave Yard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Oxford Control Measures Data Set (Ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
