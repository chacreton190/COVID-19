{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID Government Response Paper Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "\n",
    "\n",
    "- [ ] Continue to update this **[file](https://1drv.ms/x/s!AjWX5HOdYY23kf9x5S7g8LKLGlseVg?e=992nsi)** of data source locations \n",
    "- [ ] Figure out what to do about the negative values for case counts and death counts\n",
    "- [ ] Continue to review the tutorial here [How to run a Zero-inflated Model with Random Effects](https://stats.idre.ucla.edu/sas/faq/how-do-i-run-a-random-effect-zero-inflated-poisson-model-using-nlmixed/)\n",
    "- [ ] Figure out how to lag the case and death vars\n",
    "- [ ] fill forward all of the control measures vars for all of the countries with data on these vars\n",
    "- [ ] formalize the sensitivity analysis for the different thresholds for classifying SARS exp\n",
    "\n",
    "### Completed:\n",
    "- [X] Need to explore the missingness of the Oxford data. Sort the countries by GDP and examine what the missingness matrix looks like. **If you could run imputation on this data then you would have a major leg up on the other paper working on the similar topic. (on to of the other benefits to your paper)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] =15 ,9\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import missingno as msno\n",
    "import re\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '..\\Modified Data Sets'\n",
    "control_data_path = '..\\Control Data'\n",
    "graphics_path = '..\\graphics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing main data set\n",
    "df_path = glob(f'{data_path}\\Final COVID Data Set (Through*.xlsx')[0]\n",
    "df = pd.read_excel(df_path)\n",
    "df = df.loc[(~df.date.isnull())]\n",
    "\n",
    "#Creating data set to analyze missingness\n",
    "no_dup = df.copy()\n",
    "no_dup = no_dup.loc[~no_dup.case_count.isnull()]\n",
    "no_dup['dup'] = no_dup.duplicated(['country'],keep='last')\n",
    "miss_anal = no_dup.loc[~no_dup.dup]\n",
    "miss_anal = miss_anal.loc[~miss_anal.quarantine_efficiency.isnull()]\n",
    "#Creating dataset to analyze the overall trend\n",
    "df_indexed = (df.groupby(by='date').sum()).filter(items=['case_count','death_count'])\n",
    "df_indexed = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Negative Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axhline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.country == 'USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'france'\n",
    "var = 'Case Count'\n",
    "y_var1 = 'case_rol_mean7'\n",
    "y_var2 = 'death_rol_mean7'\n",
    "c = df.loc[df.country.str.contains(country,re.IGNORECASE)]\n",
    "ax = sns.lineplot( x='date',y=y_var1,data=c,label=y_var1)\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot( x='date',y=y_var2,data=c, ax=ax2, color='black', label=y_var2)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(var)\n",
    "plt.axhline(0, c='black')\n",
    "plt.title(f'County-level Daily COVID-19 {var} for {c.country.unique()[0][0].upper()}{c.country.unique()[0][1:].lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var = '7-Day Rolling Mean'\n",
    "c = df.loc[df.country.str.contains(country,re.IGNORECASE)]\n",
    "sns.lineplot( x='date',y=y_var,data=c,label=var)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(var)\n",
    "plt.axhline(0, c='black')\n",
    "plt.title(f'County-level Daily COVID-19 {var} for {c.country.unique()[0][0].upper()}{c.country.unique()[0][1:].lower()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Evaluating Stationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# dftest = adfuller(df_indexed.case_count,autolag='AIC')\n",
    "# dfoutput = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'n'])\n",
    "# for key,value in dftest[4].items():\n",
    "#     dfoutput[f'Critical Value ({key})']= value\n",
    "# print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'date', y ='case_count', hue = 'country', data = df,legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'date', y ='death_count', hue = 'country', data = df,legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolmean = df_indexed.case_count.rolling(window=7).mean()\n",
    "rolstd = df_indexed.case_count.rolling(window=7).std()\n",
    "rolmean.plot()\n",
    "rolstd.plot()\n",
    "plt.title('Global Case Count Rolling Mean & STD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolmean = df_indexed.death_count.rolling(window=7).mean()\n",
    "rolstd = df_indexed.death_count.rolling(window=7).std()\n",
    "mean = plt.plot(rolmean, label='Rolling Mean')\n",
    "std = plt.plot(rolstd, label='Rolling STD')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Global Death Count Rolling Mean & STD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolmean = df_indexed.death_count.rolling(window=7).mean()\n",
    "\n",
    "# rolstd = df_indexed.death_count.rolling(window=7).std()\n",
    "# rolmean.plot( label='Rolling Mean')\n",
    "# rolstd.plot( label='Rolling STD')\n",
    "\n",
    "# # death = plt.plot(df_indexed.death_count, label = 'Death Counts')\n",
    "# plt.legend(loc='best')\n",
    "# plt.title('Rolling Mean & STD')\n",
    "# # rolstd.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### Missingness Sorted by GDP Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_anal.sort_values(by='gdp_rank',inplace=True)\n",
    "df_nomiss = miss_anal.loc[~miss_anal.case_count.isnull()].copy()\n",
    "msno.matrix(df_nomiss, color=(0.0, 0.10, 0.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nomiss_cc = df_nomiss.loc[~df_nomiss.school_close.isnull()].copy()\n",
    "msno.matrix(df_nomiss_cc, color=(0.0, 0.30, 0.00))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### Missingness Sorted by Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df_nomiss, color=(0.0, 0.00, 0.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df_nomiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(df_nomiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.case_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.death_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "sns.pairplot(df, vars= ['case_count','pop_2020', 'mers_sars_sum','school_close','large_gather','internat_travel','public_events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars= ['death_count','pop_2020', 'gdp_rank','ages_65_and_above_of_total_population','public_events'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.distplot(df.case_count)\n",
    "plt.title('Distribution of Global Daily COVID-19 Case Counts')\n",
    "plt.rcParams['figure.figsize'] = (25,10) # changes plot size\n",
    "plt.xlabel('Case Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.death_count)\n",
    "plt.title('Distribution of Global Daily COVID-19 Case Counts')\n",
    "plt.rcParams['figure.figsize'] = (25,10) # changes plot size\n",
    "plt.xlabel('Case Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on the Fitted values for the Irma Arbo Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irma_dist_path = r\"C:\\Users\\chacr\\OneDrive\\USF\\Misc Research\\GA Work\\Data Analysis\\Final Analysis SAS Data sets\\COUNT DATASET\\Data sets\\Irma Eye Distance 2-8-20.xlsx\"\n",
    "fitted_path = r\"C:\\Users\\chacr\\OneDrive\\USF\\Misc Research\\GA Work\\Data Analysis\\Final Analysis SAS Data sets\\COUNT DATASET\\Exported Datasets\\Fitted Values For Model(Var Storm Dist)11-1-20.xlsx\"\n",
    "irma= pd.read_excel(irma_dist_path)\n",
    "irma.columns = irma.columns.str.lower()\n",
    "fitted = pd.read_excel(fitted_path)\n",
    "fitted.columns = fitted.columns.str.lower()\n",
    "irma['sed_km'] = round(irma.storm_eye_dist/1000,3)\n",
    "irma.sort_values(by='sed_km')\n",
    "irma_fitted = irma.merge(fitted,left_on='sed_km',right_on='storm_eye_dist_km')\n",
    "irma_fitted.drop(columns=['storm_eye_dist_km','stmtno'],inplace=True)\n",
    "for dists in distlist:\n",
    "    print(f'lsmeans post_h /at STORM_EYE_DIST_KM =({dists}) ilink diff;')\n",
    "distlist = list(irma.sed_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irma_fitted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irma_fitted.to_csv(r\"C:\\Users\\chacr\\OneDrive\\USF\\Misc Research\\GA Work\\Data Analysis\\Final Analysis SAS Data sets\\COUNT DATASET\\Exported Datasets\\Fitted Values & Storm Distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='sed_km', y='mu_pre', data =irma_fitted)\n",
    "sns.lineplot(x='sed_km', y='mu_post', data =irma_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\tag{2.13}\n",
    "stack.loss_i = \\alpha_n + \\beta air_i + e_i, \\text{ where } e_i \\sim \\text{N}(0,\\sigma^2) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\tag{2.7}\n",
    "\\begin{bmatrix}stack.loss_1\\\\stack.loss_2\\\\stack.loss_3\\\\stack.loss_4\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "\\alpha&\\beta&0&0&0\\\\\n",
    "\\alpha&0&\\beta&0&0\\\\\n",
    "\\alpha&0&0&\\beta&0\\\\\n",
    "\\alpha&0&0&0&\\beta\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}1\\\\air_1\\\\air_2\\\\air_3\\\\air_4\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}e_1\\\\e_2\\\\e_3\\\\e_4\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[\\begin{equation}\\tag{2.7}\\begin{bmatrix}stack.loss_1\\\\stack.loss_2\\\\stack.loss_3\\\\stack.loss_4\\end{bmatrix}=\\begin{bmatrix}\\alpha&\\beta&0&0&0\\\\ \\alpha&0&\\beta&0&0\\\\ \\alpha&0&0&\\beta&0\\\\ \\alpha&0&0&0&\\beta\\end{bmatrix}\n",
    "\\end{equation}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
